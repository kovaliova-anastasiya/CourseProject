% http://manpages.ubuntu.com/manpages/cosmic/man7/sched.7.html
% https://www.ibm.com/developerworks/ru/library/l-scheduler/index.html
\subsubsection{До версии ядра Linux 2.6}
До выхода ядра версии 2.6 Linux системы использовали планировщик задач, который назывался \textbf{O(n)} \cite{ibmLinux}. Все процессы хранились в общей очереди, а процессорное время делилось на ''эпохи''. Каждый из процессов мог выполняться в течение присвоенного ему кванта времени. Если процесс не использовал свой квант до конца и досрочно перешел в состояние блокировки, то наследующей эпохе, когда ему выделится ЦП, этот процесс получит дополнительное время. Если процесс квант израсходовал полностью, то на следующей эпохе его квант обновится.

Достоинства:
\begin{enumerate}[label=---]
\item Простота понимания и реализации.
\item Попытка компенсировать процессам, ограниченным скоростью работы устройств ввода-вывода, не израсходованное процессорное время.
\end{enumerate}

Недостатки:
\begin{enumerate}[label=---]
\item Линейное от количества процессов в системе время работы. Алгоритм, чтобы выбрать новый процесс для исполнения, просматривает все процессы в очереди, чтобы найти процесс, который еще не выполнялся на данной эпохе. Таким образом, при большом числе процессов планировщик тратит много процессорного времени на потребности планирования вместо полезной работы, а это плохо.

\item В многопроцессорных системах при алгоритме планирования ''O(n)'' процесс мог быть назначен на исполнение любому из процессоров. Это приводило к проблеме ''холодного старта'': задача назначена на один процессор, а ее данные находятся в кэше процессора, на котором она выполнялась до этого. Данные необходимо переместить, а это требует дополнительных затрат. Проблему можно частично решить, сохраняя информацию о процессоре, на котором исполнялся процесс, в дескрипторе процесса, затем назначать процесс на тот же процессор. Однако, такой подход серьезно усложнит алгоритм (ожидание освобождение ''своего'' процессора).

\item В многопроцессорных системах появляется проблема синхронизации процессоров: несколько процессоров одновременно требуют доступа к очереди процессов. Их работу необходимо согласовывать с помощью объектов синхронизации, в которые помещается очередь процессов. Такой подход не является эффективным: пока один процессор работает с очередью, что занимает в худшем случае O(n) времени, остальные процессоры могут простаивать и не выполняют полезной работы.
    
\end{enumerate}
В силу изложенных выше недостатков стала очевидна необходимость совершенствования алгоритма планирования, что реализовывалось в последующих версиях ядра.

\subsubsection{Версия ядра Linux 2.6}
В этой версии ядра на смену алгоритму ''O(n)'' пришел алгоритм ''O(1)'' \cite{ibmLinux}. Алгоритм является дальнейшим развитием модификации циклической схемы [см. \ref{int:cyclical}].\\
Присвоим каждому процессу квант времени и приоритет: чем меньше числовое значение, тем выше приоритет.
За процессором закрепим структуру LIL, обозначим ее $L_{Active} =  L_A$, а ее элементы - $L_{A_i}, i = 0..139$. Каждый $L_{A_i}$ будет хранить процессы с приоритетом $i$, которые не исчерпали свой квант. Аналогично введем структуру LIL с именем $L_{Blocked} = L_B$, в которой будем хранить классы приоритетов с процессами, исчерпавшими свой квант.\\

Пусть $bit-array$ - битовый массив, такой, что его бит с номером $i$ принимает значение 1, если  $L_{A_i}$ не пуст, иначе 0. \\
При планировании будет выбираться не пустой $L_{A_i}:i \rightarrow min$ (класс с наивысшим приоритетом), а внутри класса применяется циклическая схема. Сделать такой выбор можно с помощью применения операции $find-first-bit-set$ к $bit-array$, которую поддерживает большинство архитектур процессоров. После перехода активного процесса в состояние блокировки происходит пересчет его кванта и приоритета. В зависимости от значения кванта, процесс будет помещаться в одну из структур $L_{A}, L_B$.Если процесс помещен в $L_B$, сразу обновим его квант. Но совсем не обязательно, что процесс попадет в ячейку с тем же номером, что и ранее: планировщик учитывает специфику процесса (например, как быстро после активации перешел в состояние блокировки) и соответствующим образом изменяет его класс приоритета (справедливо только для пользовательских задач, классы реального времени не затрагиваются). Также применяется механизм вытеснения: если при выполнении процесса из некоторой группы с приоритетом $i$, в группе с приоритетом $j$ появится готовый к выполнению процесс и при этом $i > j$ (приоритет $j$ выше $i$), то произойдет досрочная замена исполняющегося процесса на более приоритетный (вытеснение процесса).
Когда все $L_{A_i}$ опустеют, поменяем $L_A, L_B$ местами и продолжим планирование.\\ 
Недостатки:
\begin{enumerate}[label=---]
\item Процессы из групп с низким приоритетом могут ''голодать'' , если в системе много процессов с более высоким приоритетом. Как отмечалось, планировщик может изменять приоритеты процессов, тогда этот недостаток можно частично компенсировать понижением приоритетов остальных процессов или повышением приоритета данной группы. Как реализовать систему динамических приоритетов, будет показано позже [см. \ref{unix:priority}].
\end{enumerate}

\subsubsection{Версия ядра Linux 2.6.23}
\label{linux:cfs}
В версии ядра 2.6.23 введен алгоритм \textit{Completely Fair Scheduler (CFS)} \cite{ibmLinuxCFS} \cite{lav}, базой которого является упрощение ''справедливого'' алгоритма [см. \ref{int:fair}]. CFS дополнительно вводит понятие \textbf{минимальной детализации} - минимальный отрезок времени, в течение которого будет выполняться процесс. Это сделано для того, чтобы минимизировать издержки на смену контекста при увеличении числа процессов.\\
Главным недостатком такого подхода в пользовательской системе я считаю ''теоретически'' недостаточный уровень интерактивности, так как процессорное время делится между всеми процессами поровну, как итог, оборотное время увеличивается. С другой стороны, CFS будет полезно использовать в ситуациях, когда нужно сбалансировать процессы по потреблению ресурсов (например, сервер, обрабатывающий пользовательские запросы). CFS решает проблему процессов, ограниченных скоростью работы устройств ввода-вывода, за счет того, что после выхода из блокировки такого процесса он вскоре получит процессорное время, поскольку его доля суммарного израсходованного времени будет меньше необходимой.
